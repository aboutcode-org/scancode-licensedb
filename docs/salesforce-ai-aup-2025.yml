key: salesforce-ai-aup-2025
short_name: Salesforce AI Acceptable Use Policy 2025
name: Salesforce Artificial Intelligence Acceptable Use Policy 2025
category: Proprietary Free
owner: Salesforce.com
homepage_url: https://www.salesforce.com/content/dam/web/en_us/www/documents/legal/Agreements/policies/ai-acceptable-use-policy.pdf
spdx_license_key: LicenseRef-scancode-salesforce-ai-aup-2025
other_urls:
  - https://github.com/search?q=org%3Asalesforce+Ethics+disclaimer+for+Salesforce+AI+models%2C+data%2C+code&type=code
ignorable_urls:
  - http://salesforce.com/
  - https://www.salesforce.com/company/legal/agreements/
text: "Salesforce Artificial Intelligence Acceptable Use Policy\n\n1. Scope\n\n A. This Artificial\
  \ Intelligence Acceptable Use Policy (“Policy”) applies to customers’ use of all services\
  \ offered by\n Salesforce, Inc. or its affiliates (“Salesforce”), or third party products,\
  \ applications or functionality that interoperate\n with services offered by Salesforce, that\
  \ incorporate artificial intelligence (collectively, “Covered AI Services”). \n Within the\
  \ Covered AI Services, those that use Generative AI will be referred to as the “Covered Generative\
  \ AI Services.” \n The terms of this Policy are in addition to the Acceptable Use and External\
  \ Facing Services Policy at\n https://www.salesforce.com/company/legal/agreements/ .\n\n 2.\
  \ Last Updated\n\n A. August 5, 2025\n\n 3. Changes to Policy\n\n A. Salesforce may change\
  \ this Policy by posting an updated version of the Policy at http://salesforce.com and such\n\
  \ updates will be effective upon posting.\n\n 4. Violations\n\n A. A customer’s violation\
  \ of this Policy will be considered a material breach of the Main Services Agreement (“MSA”)\n\
  \ and/or other agreement governing the customer’s use of the services.\n\n 5. Disallowed Usage:\n\
  \n A. Customers may not use a Covered AI Service, nor allow their users or any third party\
  \ to use a Covered AI Service,\n for the following:\n\n I. Automated Decision-Making Processes\
  \ with Legal Effects\n\n a. As part of an automated decision-making process with legal or\
  \ similarly significant effects, unless:\n\n i. Customer ensures that the final decision is\
  \ made by a human being and takes other factors\n beyond the Services’ recommendation into\
  \ account; and\n\n ii. Customer is transparent about the role of the Covered AI Service and\
  \ the logic involved in the\n decision-making process, including providing subjects of the\
  \ decision with the right to receive an\n explanation of the role of the Covered AI Service\
  \ in the decision-making and the main reasons\n for the decision.\n\n b. As part of an automated\
  \ decision-making process for payday lending even when the final decision is\n made by a human\
  \ being.\n\n II. Individualized Advice from Licensed Professionals\n\n a. Generating individualized\
  \ advice that in the ordinary course of business would be provided by a licensed\n professional.\
  \ This includes, for example, financial and legal advice.\n\n b. Generating or providing individualized\
  \ medical advice, treatment, or diagnosis to a consumer or end\n user.\n\n c. For clarity,\
  \ this section does not limit Customer from using Covered AI Services for other purposes,\
  \ such\n as customer support in regulated industries, or to assist a licensed professional\
  \ where Covered AI\n Services were not leveraged in the generation of individual advice. When\
  \ a Customer uses such services\n to assist in providing individualized advice (e.g., summarization),\
  \ there must be a qualified person\n reviewing the output.\n\n III. Explicitly Predicting\
  \ Or Categorizing Based On Protected Characteristics\n\n a. Explicitly predicting, or categorizing\
  \ based on an individual’s protected characteristic, including, but not\n limited to, racial\
  \ or ethnic origin, and past, current, or future political opinions, religious or philosophical\n\
  \ beliefs, trade union membership, age, gender, sex life, sexual orientation, disability,\
  \ health status,\n medical condition, financial status, criminal convictions, or likelihood\
  \ to engage in criminal acts.\n\n i. The previous sentence does not limit or prohibit use\
  \ cases or tools designed specifically to\n identify security breaches, unauthorized access,\
  \ fraud, and other security vulnerabilities, or to\n identify and reduce bias in Salesforce\
  \ AI Services.\n\n ii. Additionally, Customer may not submit images, videos or audio recordings\
  \ of individuals for the\n purposes of creating , analyzing, or categorizing based on, biometric\
  \ identifiers, such as face\n prints or fingerprints or scans of eyes, hands, voiceprints,or\
  \ facial geometry.\n\n IV. Social Scoring and Crime Prediction\n\n a. Evaluating, classifying,\
  \ scoring or rating individuals or groups based on their social behavior or\n personality\
  \ characteristics where such scoring leads to:\n\n i. Detrimental or unfavorable treatment\
  \ unrelated to the original context of the collected data; or\n\n ii. Unjustified or disproportionate\
  \ treatment relative to the assessed behavior.\n\n b. Assessing or predicting the risk of\
  \ an individual committing a criminal offense, based solely on profiling\n or assessing their\
  \ personality traits and characteristics.\n\n V. Emotion and Facial Recognition\n\n a. Detecting,\
  \ inferring, or assessing individuals’ emotions in the workplace or in educational institutions,\n\
  \ except for medical or safety reasons.\n\n b. Creating or expanding facial recognition databases,\
  \ e.g., through scraping of facial images from the\n Internet or from CCTV footage.\n\n c.\
  \ Using real-time biometric recognition in public spaces for law enforcement purposes, unless\
  \ an\n exception is expressly permitted by applicable law (e.g., to prevent a serious threat\
  \ or find a missing\n person).\n\n VI. Deceptive Activity\n\n a. Engaging in plagiarism or\
  \ academic dishonesty.\n\n b. Deploying subliminal, purposefully manipulative or deceptive\
  \ techniques that impair an individual’s\n ability to make an informed decision.\n\n c. Exploiting\
  \ vulnerabilities of individuals, e.g., due to their age, disability or specific social or\
  \ economic\n situation.\n\n VII. Child Exploitation and Abuse\n\n a. Creating, sending, uploading,\
  \ displaying, storing, processing, or transmitting material that may be\n harmful to minors\
  \ including, but not limited to, for any purposes related to child exploitation or abuse,\n\
  \ such as real or artificial Child Sexual Abuse Material (CSAM).\n\n B. Customers may not\
  \ use a Covered Generative AI Service, nor allow its users or any third party to use any Covered\n\
  \ Generative AI Services, for the following:\n\n I. Weapons Development\n\n a. Developing,\
  \ advertising, marketing, distributing, or selling weapons, weapon accessories, or explosives,\n\
  \ as enumerated by the United States Munitions List .\n \n II. Political Campaigns\n\n a.\
  \ Targeting, creating, or distributing political campaign materials for external public or\
  \ semi-public\n audiences. Political campaign material refers to material:\n\n i. That may\
  \ influence a political process, such as an election, passage of legislation, regulation or\n\
  \ ballot measure, judicial ruling, and content for campaigning purposes; or\n\n ii. Soliciting\
  \ financial support for (i).\n\n III. Adult Content\n\n a. Creating, sending, uploading, displaying,\
  \ storing, processing, or transmitting sexually explicit material;\n\n b. Creating, sending,\
  \ uploading, displaying, storing, processing, or transmitting sexual chatbots or engaging\n\
  \ in erotic chat.\n\n 6. Use Notice and Disclosures\n\n A. USE NOTICE: AI technology, including\
  \ Generative AI, will continue to be used in new and innovative ways. Customer\n is responsible\
  \ for determining if its use of these technologies is safe.\n\n B. Customers must disclose\
  \ to end users when they are interacting directly with automated systems, such as Einstein\n\
  \ bots, Agentforce Agents, or similar features including voice- or call-based bots unless\
  \ there is a human in the loop,\n and when required by law, provide a means for end users\
  \ to interact with a human instead of an automated system.\n\n C. Customers must disclose\
  \ to individuals when exposing them, for the limited purpose permitted in this Policy, to\
  \ an\n emotion recognition system or a biometric categorization system.\n\n D. Customers may\
  \ not deceive end users or consumers by misrepresenting content generated through automated\n\
  \ means as human generated or original content.\n"
